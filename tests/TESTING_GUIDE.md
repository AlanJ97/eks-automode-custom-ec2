# Gu√≠a de Testing para EKS Auto Mode

## 0. Prerrequisitos
Antes de iniciar:
- Cl√∫ster EKS (repo1) listo y accesible (contexto de `kubectl` correcto).
- NodeClass / NodePool (repo2) aplicados (NodePool con l√≠mite CPU=24 / Mem=48Gi).
- Regla **puerto 443 SG‚ÜíSG** existente (desde VPC) para que los nodos se registren.
- (Opcional) M√©tricas habilitadas (`kubectl top`) v√≠a Metrics Server si se desean datos de uso.

Si la carpeta de manifiestos cambi√≥ a `test/` en vez de `tests/`, sustituye la ruta en los comandos (ambos nombres se mencionan aqu√≠). Verifica con:
```bash
ls -1 test 2>/dev/null || ls -1 tests
```

## 1. Tipos de Tests Recomendados

### 1. **Tests de Escalado Horizontal (Node Provisioning)**
Objetivo: Validar que Karpenter provisiona nuevos nodos c7i.xlarge cuando hay demanda.

**Indicadores a medir:**
- Tiempo de provisi√≥n de nuevos nodos
- Correcta selecci√≥n del tipo de instancia (c7i.xlarge)
- Distribuci√≥n entre zonas de disponibilidad
- Capacidad on-demand vs spot (si aplica)

### 2. **Tests de Estr√©s de CPU/Memoria**
Objetivo: Verificar que los nodos manejan cargas intensivas y escalan apropiadamente.

**M√©tricas importantes:**
- Utilizaci√≥n de CPU/memoria por nodo
- Latencia de respuesta bajo carga
- Estabilidad del cluster durante picos

### 3. **Tests de Escalado Din√°mico (HPA)**
Objetivo: Validar que el Horizontal Pod Autoscaler funciona correctamente con Auto Mode.

**Comportamientos esperados:**
- Scale-up cuando la utilizaci√≥n supera umbrales
- Scale-down gradual cuando la carga disminuye
- Respeto a l√≠mites m√≠nimos/m√°ximos

### 4. **Tests de Resiliencia**
Objetivo: Verificar recuperaci√≥n ante fallos y comportamiento en escenarios adversos.

**Escenarios a probar:**
- Terminaci√≥n abrupta de nodos
- Pods sin recursos suficientes
- Network partitions temporales

## 2. Flujo Sugerido de Prueba de Escalado M√°ximo (Paso a Paso) ‚≠ê
Objetivo: Forzar creaci√≥n de nodos hasta alcanzar el l√≠mite (‚âà 6 nodos c7i.xlarge) y validar consolidaci√≥n.

1. Estado inicial (cero o pocos nodos de workload):
  ```bash
  kubectl get nodes -o wide
  kubectl get nodeclaim,nodepool -A
  ```
2. Aplicar despliegue de estr√©s base (crea 6 r√©plicas con CPU sostenida):
  ```bash
  kubectl apply -f tests/stress-test.yaml
  # o si est√° en carpeta singular
  kubectl apply -f test/stress-test.yaml
  ```
3. Esperar 1‚Äì3 minutos y observar NodeClaims creados:
  ```bash
  watch -n 15 'kubectl get nodeclaim; echo "---"; kubectl get nodes -o wide | grep c7i'
  ```
4. A√±adir carga de memoria para diversificar uso de recursos:
  ```bash
  kubectl apply -f tests/memory-test.yaml
  ```
5. Activar HPA para inducir aumentos de r√©plicas din√°micos (sobre el deployment stress-test):
  ```bash
  kubectl apply -f tests/hpa-test.yaml
  ```
6. (Opcional) Escalar manualmente para acelerar demanda:
  ```bash
  kubectl scale deployment stress-test --replicas=12
  kubectl scale deployment memory-test --replicas=8
  ```
7. Validar que no se superen los l√≠mites del NodePool (observa que, al alcanzar ~24 vCPU solicitados, se detiene el incremento de nodos):
  ```bash
  kubectl describe nodepool c7i-xlarge-pool | grep -i limit -A3
  ```
8. Confirmar distribuci√≥n multi-AZ (etiqueta `topology.kubernetes.io/zone`):
  ```bash
  kubectl get nodes -L topology.kubernetes.io/zone -o wide
  ```
9. Revisar eventos recientes (creaci√≥n / consolidaci√≥n / underutilized):
  ```bash
  kubectl get events --sort-by=.lastTimestamp | grep -i -E 'Karpenter|Consolidat' | tail -30
  ```
10. (Tras la prueba) Reducir r√©plicas para observar consolidaci√≥n (si no hay carga, nodos se liberan):
   ```bash
   kubectl scale deployment stress-test --replicas=0
   kubectl scale deployment memory-test --replicas=0
   ```
11. Esperar periodo de `consolidateAfter` (60s) + tiempo de terminaci√≥n y verificar nodos removidos:
   ```bash
   watch -n 20 'kubectl get nodes; echo "---"; kubectl get nodeclaim'
   ```

üìå Nota: La consolidaci√≥n solo elimina nodos cuando est√°n vac√≠os o infrautilizados seg√∫n l√≥gica de Karpenter.

## 3. C√≥mo Ejecutar los Tests

### Opci√≥n 1: Script Automatizado (Recomendado)
Dispones de dos variantes seg√∫n el sistema:

| Script | Entorno | Ejemplo de uso |
|--------|---------|----------------|
| `test-auto-mode.ps1` | Windows PowerShell | `./test-auto-mode.ps1` |
| `test-auto-mode.sh`  | Linux / macOS / Git Bash | `bash tests/test-auto-mode.sh --menu` |

Modos del script bash:
```
--quick      # Jobs r√°pidos (super / quick)
--stress     # stress + memory + hpa (~5 min monitoreo)
--complete   # Flujo completo (estado, despliegue, escala, resultados)
--cleanup    # Limpieza de workloads
--menu       # Men√∫ interactivo (por defecto)
```
Ejemplo r√°pido (Git Bash):
```bash
chmod +x tests/test-auto-mode.sh
bash tests/test-auto-mode.sh --stress
```
Si `kubectl` no se detecta en Git Bash, aseg√∫rate de que est√© en el PATH o ejecuta primero desde PowerShell para confirmar acceso.
```powershell
# Ejecutar el suite completo de tests
.\test-auto-mode.ps1
```

### Opci√≥n 2: Tests Manuales

#### Test Ultra-R√°pido (3 minutos)
```bash
# 1. Estado inicial
kubectl get nodes
kubectl get nodeclaim,nodepool

# 2. Aplicar test super r√°pido
kubectl apply -f tests/super-quick-test.yaml

# 3. Monitorear
kubectl get pods -w
# En otra terminal: kubectl get nodes -w

# 4. Limpiar
kubectl delete -f tests/super-quick-test.yaml
```

#### Test R√°pido (5 minutos)
```bash
# 1. Estado inicial
kubectl get nodes
kubectl get nodeclaim,nodepool

# 2. Aplicar test r√°pido
kubectl apply -f tests/quick-test.yaml

# 3. Monitorear
kubectl get pods -w
kubectl get nodes -w

# 4. Limpiar
kubectl delete -f tests/quick-test.yaml
```

#### Test de Estr√©s (7 minutos m√°ximo)
```bash
# 1. Aplicar cargas de trabajo
kubectl apply -f tests/stress-test.yaml
kubectl apply -f tests/memory-test.yaml

# 2. Monitorear escalado
watch -n 30 'kubectl get nodes; echo "---"; kubectl get pods; echo "---"; kubectl top nodes'

# 3. Generar m√°s carga (opcional)
kubectl scale deployment stress-test --replicas=12

# 4. Observar provisi√≥n de nodos
kubectl get events --sort-by='.lastTimestamp' | tail -20
```

#### Test con HPA (7 minutos m√°ximo)
```bash
# 1. Aplicar HPA
kubectl apply -f tests/hpa-test.yaml

# 2. Generar carga variable
kubectl apply -f tests/stress-test.yaml

# 3. Monitorear comportamiento
kubectl get hpa -w
kubectl get pods -w
```

## 4. Comandos de Monitoreo √ötiles

### Estado General
```bash
# Nodos y capacidad
kubectl get nodes -o wide
kubectl describe nodes

# NodeClaims de Karpenter
kubectl get nodeclaim -o wide
kubectl describe nodeclaim

# Utilizaci√≥n de recursos
kubectl top nodes
kubectl top pods
```

### Eventos y Logs
```bash
# Eventos recientes de Karpenter
kubectl get events --sort-by='.lastTimestamp' | grep -i karpenter

# Logs de Karpenter (si accesible)
kubectl logs -n karpenter deployment/karpenter

# Estado de los NodePools
kubectl describe nodepool c7i-xlarge-pool
```

### Debugging
```bash
# Pods que no pueden ser programados
kubectl get pods --field-selector=status.phase=Pending

# Describe pod para ver razones
kubectl describe pod <pod-name>

# Ver restricciones de nodos
kubectl get nodes --show-labels
```

## 5. M√©tricas de √âxito

### ‚úÖ Indicadores Positivos
- **Tiempo de provisi√≥n**: Nuevos nodos c7i.xlarge aparecen en < 5 minutos
- **Precisi√≥n de tipo**: Solo instancias c7i.xlarge son provisionadas
- **Distribuci√≥n de zona**: Nodos se distribuyen entre us-west-1a y us-west-1b
- **Programaci√≥n de pods**: Pods pendientes se programan r√°pidamente
- **Estabilidad**: No hay crashloops o errores persistentes

### ‚ùå Se√±ales de Problemas
- Nodos de tipos incorrectos (no c7i.xlarge)
- Tiempo de provisi√≥n > 10 minutos
- Pods que permanecen en estado Pending > 5 minutos
- Errores de autorizaci√≥n en eventos de Karpenter
- Nodos que no se unen al cluster

## 6. Scripts de Limpieza

### Limpiar Tests Espec√≠ficos
```bash
kubectl delete -f tests/stress-test.yaml
kubectl delete -f tests/memory-test.yaml
kubectl delete -f tests/hpa-test.yaml
kubectl delete -f tests/quick-test.yaml
```

### Limpiar Nodos Manualmente (Si Necesario)
```bash
# Ver NodeClaims activos
kubectl get nodeclaim

# Eliminar NodeClaim espec√≠fico (forzar√° terminaci√≥n del nodo)
kubectl delete nodeclaim <nodeclaim-name>
```

## 7. Interpretaci√≥n de Resultados

### Escenario Normal
```
NODES: 2-3 nodos c7i.xlarge
PODS: La mayor√≠a en estado Running
EVENTS: "Successfully launched nodeclaim"
TIMING: Nuevos nodos en 3-5 minutos
```

### Escenario con Problemas
```
NODES: Nodos no aparecen o tipos incorrectos
PODS: Muchos en estado Pending
EVENTS: Errores de autorizaci√≥n o l√≠mites
TIMING: > 10 minutos sin provisi√≥n
```

## 8. Consideraciones de Costo

**‚ö†Ô∏è IMPORTANTE**: Los tests generar√°n costo por:
- Instancias EC2 c7i.xlarge ($0.2448/hora por instancia)
- Tr√°fico de red entre AZs
- Almacenamiento EBS asociado

**Recomendaci√≥n**: Ejecutar tests en horarios planificados y limpiar recursos inmediatamente despu√©s.

## 9. Automatizaci√≥n y CI/CD

Para integrar estos tests en pipelines:

```yaml
# Ejemplo para GitHub Actions o similar
test-auto-mode:
  steps:
    - name: Deploy test workloads
      run: kubectl apply -f tests/
    
    - name: Wait for scaling
      run: sleep 300
    
    - name: Validate nodes
      run: |
        NODE_COUNT=$(kubectl get nodes --no-headers | wc -l)
        if [ $NODE_COUNT -lt 2 ]; then
          echo "ERROR: Expected at least 2 nodes"
          exit 1
        fi
    
    - name: Cleanup
      run: kubectl delete -f tests/
      if: always()
```

## 10. Buenas Pr√°cticas Operativas
| Pr√°ctica | Raz√≥n |
|----------|-------|
| Limitar replicas iniciales | Evita picos de costo inesperados |
| Revisar eventos antes de escalar m√°s | Detecta throttling / permisos |
| Registrar tiempos de provisi√≥n | M√©trica clave para SLO interno |
| Limpiar workloads tras cada experimento | Minimiza gastos |
| Verificar `kubectl get nodeclaim` vs `kubectl get nodes` | Detecta retrasos de join |

## 11. Notas sobre Add-on EBS CSI DEGRADADO
Si en la consola el add-on EBS CSI aparece DEGRADADO pero el cl√∫ster y NodePool est√°n operativos:
- Puedes proceder con estas pruebas: la actividad (creaci√≥n de pods con vol√∫menes futuros) y/o un re-aplicar del m√≥dulo de cl√∫ster suelen normalizarlo.
- Si Terraform qued√≥ esperando m√°s de 20 minutos, cancelar (Ctrl+C) y continuar con pruebas no afecta este flujo.

---
Esta gu√≠a proporciona un framework completo para validar que tu EKS Auto Mode funciona correctamente con instancias c7i.xlarge y l√≠mites definidos.
